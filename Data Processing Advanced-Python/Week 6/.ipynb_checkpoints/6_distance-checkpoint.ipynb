{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Distance and similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance metrics\n",
    "\n",
    "The distance metric represents the distance between two points $x$ and $y$. A point in $n$-dimensional space can be represented by a vector of length $n$. \n",
    "\n",
    "\n",
    "### Applications\n",
    "\n",
    "Some examples of applications of distance metrics:\n",
    "- k-nearest neighbors algorithm: to calculate the k points that are closest to the new unlabelled point.\n",
    "- Clustering algorithms: to calculate the distance between records inside the cluster and to calculate the distance between different clusters. For example, k-means clustering.\n",
    "\n",
    "\n",
    "Some frequently used distance metrics include:\n",
    "- Euclidean distance: $$D_{euc}(x, y) = \\left(\\sum_{i=1}^{n}(x_{i}-y_{i})^2\\right)^{0.5}$$\n",
    "- Manhattan distance: $$D_{manh}(x, y) = \\sum_{i=1}^{n} abs(x_{i}-y_{i})$$\n",
    "\n",
    "In general, distance metrics satisfy some properties such as:\n",
    "- The distance between two points is non-negative. \n",
    "- The distance from a point to the point itself is equal to 0. \n",
    "- The distance from point $i$ to point $j$ is exactly equal to the distance from point $j$ to point $i$ (symmetry). \n",
    "- The distance from point $i$ to point $j$ via point $k$ is always longer or equal than the direct distance from $i$ to $j$ (triangle inequality). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan distance:  2\n"
     ]
    }
   ],
   "source": [
    "# function to calculate manhattan distance between two points x and y\n",
    "def manhattan_distance(x, y):\n",
    "    return numpy.sum(numpy.abs(x-y))\n",
    "        \n",
    "x = numpy.array([1,3])\n",
    "y = numpy.array([2,4])\n",
    "print(\"Manhattan distance: \", manhattan_distance(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1\n",
    "\n",
    "Create a function to calculate the Euclidean distance between two points x and y. \n",
    "Do not use explicit loops.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "a = numpy.array([0.0, 0.0])\n",
    "b = numpy.array([1.0, 1.0])\n",
    "c = numpy.array([2.0, 2.0])\n",
    "print(euclidean(a, b))\n",
    "print(euclidean(a, c))\n",
    "```\n",
    "Output:\n",
    "```\n",
    "1.41421356237\n",
    "2.82842712475\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n",
      "2.8284271247461903\n"
     ]
    }
   ],
   "source": [
    "# ....................................................\n",
    "def euclidean(a, b):\n",
    "    return (np.sum((a-b)**2))**0.5\n",
    "\n",
    "a = numpy.array([0.0, 0.0])\n",
    "b = numpy.array([1.0, 1.0])\n",
    "c = numpy.array([2.0, 2.0])\n",
    "print(euclidean(a, b))\n",
    "print(euclidean(a, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.2\n",
    "\n",
    "Load the iris data into a 150x4 numpy array. Compute the Euclidean distance between the first row and each other row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# .........................\n",
    "iris = np.genfromtxt(\"iris(1).txt\")\n",
    "data = iris[:,0:4].astype(\"float\")\n",
    "print(data.shape)\n",
    "print()\n",
    "\n",
    "distance = np.array([euclidean(data[0], data[i]) for i in range(data.shape[0])])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n",
      "0.09999999999999998\n",
      "16\n",
      "[5.1 3.5 1.4 0.2]\n",
      "[5.1 3.5 1.4 0.3]\n"
     ]
    }
   ],
   "source": [
    "print(distance.shape)\n",
    "print(distance[1:].min())\n",
    "print(distance[1:].argmin())\n",
    "print(data[0])\n",
    "print(data[17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity metrics\n",
    "\n",
    "A similarity metric quantifies how similar two objects are. \n",
    "\n",
    "One often used similarity metric for vectors is the cosine similarity.\n",
    "When the cosine is equal to 1 the vectors point in the same direction, and when the cosine is equal to -1 then the vectors are the opposite of each other.\n",
    "\n",
    "Cosine similarity: $$cosine(x, y) = \\frac{x^Ty}{||x||\\cdot ||y||} = \\frac{\\sum_{i=1}^n x_i y_i}{\\left(\\sum_{i=1}^n x_{i}^2\\right)^{0.5} \\left(\\sum_{i=1}^n y_{i}^2\\right)^{0.5}}$$\n",
    "\n",
    "The cosine similarity between $x$ and $y$ is the dot product between $x$ and $y$ divided by the product of the L2-norms of $x$ and $y$.\n",
    "\n",
    "In text-mining the cosine similarity can be used to represent the similarity between two documents. We can represent documents as vectors of word counts or similar weights.\n",
    "\n",
    "High cosine similarity between two such vectors can be interpreted as these two documents sharing many words in common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.3\n",
    "Create a function that calculates the cosine similarity between two vectors. Do not use for-loops.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "a = numpy.array([0.0, 1.0])\n",
    "b = numpy.array([1.0, 0.0])\n",
    "c = numpy.array([0.0, -1.0])\n",
    "print(cosine(a, b))\n",
    "print(cosine(a, a))\n",
    "print(cosine(a, c))\n",
    "```\n",
    "Output:\n",
    "```\n",
    "0.0\n",
    "1.0\n",
    "-1.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...........................................\n",
    "def cosine(x,y):\n",
    "    return (np.transpose(x).dot(y)) /(((np.sum(x**2))**0.5) *((np.sum(y**2))**0.5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "a = numpy.array([0.0, 1.0])\n",
    "b = numpy.array([1.0, 0.0])\n",
    "c = numpy.array([0.0, -1.0])\n",
    "print(cosine(a, b))\n",
    "print(cosine(a, a))\n",
    "print(cosine(a, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance measures for comparing strings\n",
    "\n",
    "Distance measures for comparing strings with each other:\n",
    "- Hamming distance: number of positions at which two strings of the same length differ.\n",
    "    $$D_{hamming}(x, y) =  \\sum_{i=1}^{n} x_{i} \\neq y_{i} $$\n",
    "- Levenshtein distance: the minimum number of operations required to transform one string into another string. The operations are insertion, deletion and substitutions and each operations has a cost (often unit costs are used). The Levenshtein distance is commonly used when similarity between two words needs to be measured. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.3\n",
    "Create a function to calculate the Hamming distance between two strings. The strings need to have the same length.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "a = 'Panama'\n",
    "b = 'Pamela'\n",
    "hamming(a, b)\n",
    "```\n",
    "Output:\n",
    "```\n",
    "3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .....................................\n",
    "def hamming(a, b):\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError(\"Unqual string lengths\")\n",
    "    return sum((a[i] != b[i] for i in range(len(a))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'Panama'\n",
    "b = 'Pamela'\n",
    "hamming(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P', 'a', 'n', 'a', 'm', 'a']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming2(a,b):\n",
    "    a = np.array(list(a))\n",
    "    b = np.array(list(b))\n",
    "    return sum(a !=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'Panama'\n",
    "b = 'Pamela'\n",
    "hamming2(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance metrics in scikit-learn\n",
    "\n",
    "Scikit-learn is a library for machine learning algorithms in Python. Scikit-learn includes functions for classification, regression, clustering, dimensionality reduction, model selection and preprocessing. \n",
    "For more information:  http://scikit-learn.org/stable/\n",
    "\n",
    "The class to calculate distances is in the module ``neighbors`` of the scikit-learn library.\n",
    "One can access the class via: ``sklearn.neighbors.DistanceMetric``\n",
    "\n",
    "The ``DistanceMetric`` class includes different distance metrics, such as Euclidean and Manhattan, Chebyshev, Minkowski, Mahalanobis, Hamming etc.\n",
    "\n",
    "For more information about the distance metrics that are included in the ``DistanceMetric`` class:  http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html\n",
    "\n",
    "The most important methods of the ``DistanceMetric`` class are the ``get_metric`` and the ``pairwise`` functions. \n",
    "\n",
    "The ``get_metric`` function is used to specify which metric is used, for example 'euclidean' or 'manhattan'. \n",
    "The ``pairwise`` function is used to calculate the pairwise distances between points in an array x. \n",
    "\n",
    "See the examples below.\n",
    "\n",
    "There is also a simple function to calculate pairwise distances according to a number of metrics:\n",
    "```python\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance:\n",
      "[[0.         1.41421356 3.        ]\n",
      " [1.41421356 0.         2.23606798]\n",
      " [3.         2.23606798 0.        ]]\n",
      "[[0.         1.41421356 3.        ]\n",
      " [1.41421356 0.         2.23606798]\n",
      " [3.         2.23606798 0.        ]]\n",
      "Manhattan distance:\n",
      "[[0. 2. 3.]\n",
      " [2. 0. 3.]\n",
      " [3. 3. 0.]]\n",
      "[[0. 2. 3.]\n",
      " [2. 0. 3.]\n",
      " [3. 3. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.neighbors\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# we want to calculate the pairwise distance between three points in a 2D space\n",
    "x = numpy.array([[1,3], [2, 4], [1, 6]])\n",
    "\n",
    "# Euclidean distance\n",
    "d1 = sklearn.neighbors.DistanceMetric.get_metric('euclidean')\n",
    "print(\"Euclidean distance:\")\n",
    "print(d1.pairwise(x))\n",
    "print(pairwise_distances(x, metric='euclidean'))\n",
    "# Manhattan distance\n",
    "d2 = sklearn.neighbors.DistanceMetric.get_metric('manhattan')\n",
    "print(\"Manhattan distance:\")\n",
    "print(d2.pairwise(x))\n",
    "print(pairwise_distances(x, metric='manhattan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity in scipy and scikit-learn\n",
    "\n",
    "Cosine similarity is implemented in both scipy and in scikit-learn.\n",
    "\n",
    "In scipy:\n",
    "`scipy.spatial.distance.cosine(x,y)` calculates the cosine distance between two points `x` and `y` where `x` and `y` are both represented by a vector.\n",
    "\n",
    "Note that in order to convert the distance to similarity, you should subtract distance from 1.\n",
    "\n",
    "In scikit-learn:\n",
    "`sklearn.metrics.pairwise.cosine_similarity(x)` calculates the pairwise cosine similarities between all rows in array `x`.\n",
    "\n",
    "\n",
    "**IMPORTANT** Verify, and remember, which of these implementations work with sparse matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity in scipy \n",
    "\n",
    "import scipy.spatial.distance\n",
    "x = [1, 0, -1]\n",
    "y = [-1,-1, 0]\n",
    "print(1 - scipy.spatial.distance.cosine(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-0.5  1. ]]\n"
     ]
    }
   ],
   "source": [
    "# pairwise cosine similarity in sklearn\n",
    "import sklearn.metrics.pairwise\n",
    "x = numpy.array([[1, 0, -1], [-1,-1, 0]])\n",
    "print(sklearn.metrics.pairwise.cosine_similarity(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.4 \n",
    "\n",
    "Use the function `word_count` which you implemented in notebook [5_sparse.ipynb](5_sparse.ipynb) to create a document-term matrix from the first 100 rows of file [coco_val.txt](coco_val.txt). \n",
    "- Does your cosine function work on rows of the sparse document-term matrix? If not, do you know why not?\n",
    "- Compute the pairwise cosine similarity between the rows of your document-term matrix using the `sklearn` implementation. Which document is the most similar to the first row according to cosine similarity?  \n",
    "- Based on the above experiment, suggest ways of modifying the word counts to make the cosine similarity more useful as a metric of text similarity. Implement your idea and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_index(words):\n",
    "    D = {}\n",
    "    i = 0\n",
    "    for word in words:\n",
    "        if word not in D:\n",
    "            D[word] = i\n",
    "            i += 1\n",
    "    return D\n",
    "\n",
    "strings = \"A rose is a rose is a rose rose red rose\".split()\n",
    "#print(word_index(strings))\n",
    "    \n",
    "def word_count(texts):\n",
    "    words = []\n",
    "    for text in texts:\n",
    "        for word in text:\n",
    "            words.append(word)\n",
    "    vocab = word_index(words)\n",
    "    M = scipy.sparse.dok_matrix((len(texts), len(vocab)), dtype='int32')\n",
    "    # fill the matrix\n",
    "    for i in range(len(texts)):\n",
    "        for word in texts[i]:\n",
    "            j  = vocab[word]\n",
    "            M[i, j] += 1\n",
    "    return vocab, M\n",
    "text = ['All human beings are born free and equal in dignity and rights'.split(),\n",
    "       'They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood'.split()]\n",
    "vocab, M = word_count(text)\n",
    "\n",
    "print(M[0, vocab['and']])\n",
    "print(M[1, vocab['reason']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_index(words):\n",
    "    D= {}\n",
    "    i=0\n",
    "    for word in words:\n",
    "        if word not in D:\n",
    "            D[word]=i\n",
    "            i+=1\n",
    "    return D\n",
    "\n",
    "def word_count(texts):\n",
    "    words=[]\n",
    "    for text in texts:\n",
    "        for word in text:\n",
    "            words.append(word)\n",
    "    vocab = word_index(words)\n",
    "    M = scipy.sparse.dok_matrix((len(texts), len(vocab)), dtype = \"int32\")\n",
    "    \n",
    "    for i in range(len(texts)):\n",
    "        for word in texts[i]:\n",
    "            j = vocab[word]\n",
    "            M[i,j] +=1\n",
    "    return vocab, M\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "text = ['All human beings are born free and equal in dignity and rights'.split(),\n",
    "       'They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood'.split()]\n",
    "vocab, M = word_count(text)\n",
    "\n",
    "print(M[0, vocab['and']])\n",
    "print(M[1, vocab['reason']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [ line.split() for line in open(\"coco_val.txt\")][:100]\n",
    "vocab, M = word_count(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 305)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "matrix is not square",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-910f51485dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-713e28bb6ad5>\u001b[0m in \u001b[0;36mcosine\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ...........................................\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__pow__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__pow__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matrix is not square'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: matrix is not square"
     ]
    }
   ],
   "source": [
    "print(cosine(M[0,:], M[1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar sentences to texts[0] according to cossine similarity\n",
      "['a', 'child', 'holding', 'a', 'flowered', 'umbrella', 'and', 'petting', 'a', 'yak']\n",
      "['a', 'woman', 'on', 'a', 'motorcycle', 'wearing', 'a', 'bag', 'and', 'passing', 'a', 'car']\n"
     ]
    }
   ],
   "source": [
    "print(\"Most similar sentences to texts[0] according to cossine similarity\")\n",
    "S = sklearn.metrics.pairwise.cosine_similarity(M)\n",
    "j = S[0,:].argsort()[-2]\n",
    "print(texts[0])\n",
    "print(texts[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar sentence to texts[0] according to cosine similarity (remove stopwords)\n",
      "['child', 'holding', 'flowered', 'umbrella', 'petting', 'yak']\n",
      "['boy', 'holding', 'an', 'umbrella', 'while', 'standing', 'next', 'to', 'livestock']\n"
     ]
    }
   ],
   "source": [
    "# Based on the above experiment, suggest ways of modifying the word counts to make the cosine similarity more useful as a metric of text similarity. \n",
    "# Implement your idea and test it.\n",
    "print()\n",
    "print(\"Most similar sentence to texts[0] according to cosine similarity (remove stopwords)\")\n",
    "stopwords = ['a', 'and', 'the', 'is', 'in', 'on', 'at']\n",
    "texts = [ [ word for word in text if word not in stopwords] for text in texts ]\n",
    "vocab, M = word_count(texts)\n",
    "S = sklearn.metrics.pairwise.cosine_similarity(M)\n",
    "j = S[0,:].argsort()[-2]\n",
    "print(texts[0])\n",
    "print(texts[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.5\n",
    "\n",
    "Scikit learn has a couple of classes which are useful for creating various versions of document-word matrices:\n",
    "- `sklearn.feature_extraction.text.CountVectorizer`\n",
    "- `sklearn.feature_extraction.text.TfidfVectorizer`\n",
    "\n",
    "Read the documentation of these classes and try to apply them on the [coco_val.txt](coco_val.tx) data. \n",
    "- Compute similarities/distances using a few versions of these document-word matrices and check how they compare to using plain word-counts as we have been doing so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "doc = [ line.strip() for line in open('coco_val.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word counts with CountVectorizer\n",
      "Number of features: 7213\n"
     ]
    }
   ],
   "source": [
    "print(\"Word counts with CountVectorizer\")\n",
    "cv = CountVectorizer(analyzer = \"word\", lowercase=False, tokenizer= lambda x: x.split())\n",
    "M1 = cv.fit_transform(doc)\n",
    "print(\"Number of features: {}\". format(len(cv.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character n-grams with CountVectorizer\n",
      "Number of features:  75257\n"
     ]
    }
   ],
   "source": [
    "print(\"Character n-grams with CountVectorizer\")\n",
    "cvng = CountVectorizer(analyzer=\"char\", ngram_range=(1,5), lowercase=False)\n",
    "M2 = cvng.fit_transform(doc)\n",
    "print(\"Number of features: \", len(cvng.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities according to M1 vs M2\n",
      "a child holding a flowered umbrella and petting a yak\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarities according to M1 vs M2\")\n",
    "print(doc[0])\n",
    "r11 = M1[0].toarray()\n",
    "r21 = M2[0].toarray()\n",
    "for i in range(1, 20):\n",
    "    r12 = M1[i].toarray()    \n",
    "    r22 = M2[i].toarray()\n",
    "    print(\"{:.3} {:.3} {}\".format(cosine(r11, r12), cosine(r21, r22), doc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
